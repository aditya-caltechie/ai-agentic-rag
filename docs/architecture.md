
RAGChain is an Intent-Based Adaptive RAG (Retrieval-Augmented Generation) system that uses LangGraph for orchestration. Here's the complete architecture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         RAGChain System                             â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   CLI Layer  â”‚â”€â”€â”€â”€â–¶â”‚ LangGraph    â”‚â”€â”€â”€â”€â–¶â”‚  LLM Layer   â”‚         â”‚
â”‚  â”‚  (Click)     â”‚     â”‚ Orchestrator â”‚     â”‚  (Ollama)    â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚         â”‚                     â”‚                     â”‚               â”‚
â”‚         â”‚                     â–¼                     â–¼               â”‚
â”‚         â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚         â”‚            â”‚  Retrieval   â”‚â”€â”€â”€â”€â–¶â”‚  Embeddings  â”‚          â”‚
â”‚         â”‚            â”‚  Pipeline    â”‚     â”‚  (Ollama)    â”‚          â”‚
â”‚         â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                     â”‚                     â”‚               â”‚
â”‚         â–¼                     â–¼                     â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚              Storage & Vector Layer                  â”‚           â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚           â”‚
â”‚  â”‚  â”‚ Chroma DB    â”‚           â”‚    BM25      â”‚         â”‚           â”‚
â”‚  â”‚  â”‚ (Semantic)   â”‚â—€â”€â”€â”€ RRF â”€â–¶â”‚  (Keyword)   â”‚         â”‚           â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

# ğŸ“¦ Component Breakdown

## 1. Configuration Layer (config.py)
Purpose: Centralized singleton configuration management
Key Settings:
Vector store: Chroma (local or remote HTTP)
Ollama models: qwen3-embedding:4b (embeddings), qwen3:8b (generation)
Context windows: 4096 (embedding), 8192 (generation)
Retrieval parameters: k values, RRF settings
Feature flags: grading, intent routing

## 2. CLI Layer (cli.py)
Four main commands:
ingest: Load documents into vector store
search: Direct semantic search
ask: Full RAG pipeline with LLM answer generation
evaluate: LLM-as-judge evaluation framework

## 3. Ingestion Pipeline (ingestion/)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Document Ingestion Workflow                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Data Sources     â”‚
              â”‚  - Wikipedia API  â”‚
              â”‚  - TIOBE Index    â”‚
              â”‚  - Conceptual     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Document Loader  â”‚
              â”‚  (loaders.py)     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Text Splitter    â”‚
              â”‚  Chunk: 2500 ch   â”‚
              â”‚  Overlap: 500 ch  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Embeddings       â”‚
              â”‚  qwen3-embed:4b   â”‚
              â”‚  (1024 dims)      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Vector Store     â”‚
              â”‚  (Chroma DB)      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
Key Files:
loaders.py: Fetches Wikipedia articles, TIOBE rankings, conceptual pages
storage.py: Manages vector store, embeddings, and document ingestion

## 4. Retrieval Pipeline (inference/)
The core innovation is Ensemble Retrieval with Reciprocal Rank Fusion (RRF):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Ensemble Retrieval Architecture               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    User Query
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  â”‚                  â”‚
        â–¼                  â–¼                  â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  BM25   â”‚      â”‚ Chroma  â”‚      â”‚ Intent  â”‚
   â”‚ Keyword â”‚      â”‚Semantic â”‚      â”‚ Router  â”‚
   â”‚ Search  â”‚      â”‚ Search  â”‚      â”‚         â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚                â”‚                 â”‚
        â”‚                â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
                 â”‚                         â”‚
                 â–¼                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
        â”‚  RRF Fusion      â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”˜
        â”‚  score = 1/(r+60)â”‚  Weight Adjustment
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Ranked Results   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Key Features:

- BM25 Retriever: Keyword-based ranking (traditional IR)
- Chroma Retriever: Semantic vector similarity
- RRF Algorithm: Combines rankings with formula score = 1/(rank + 60)
- Intent-Based Weights:
  - FACT: 0.8 BM25 / 0.2 Chroma (keyword-heavy)
  - CONCEPT: 0.4 BM25 / 0.6 Chroma (balanced)
  - COMPARISON: 0.5 BM25 / 0.5 Chroma (semantic-leaning)
 
5. LangGraph RAG Orchestrator (inference/graph.py)
The heart of the system - a self-correcting agentic RAG workflow:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LangGraph RAG Workflow                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    START
                      â”‚
                      â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Intent Router   â”‚
            â”‚ Classify Query  â”‚
            â”‚ FACT/CONCEPT/   â”‚
            â”‚ COMPARISON      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Adaptive        â”‚
            â”‚ Retriever       â”‚
            â”‚ (Weighted RRF)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Retrieval       â”‚
            â”‚ Grader          â”‚
            â”‚ (LLM validates) â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”œâ”€â”€â”€ Grade = YES â”€â”€â”€â–¶ END (Success)
                     â”‚
                     â”œâ”€â”€â”€ Grade = NO & retry_count = 0
                     â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Query Rewriter  â”‚
            â”‚ Enhance query   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â””â”€â”€â”€â”€â–¶ Loop back to Adaptive Retriever
                            (Max 1 retry)
```

State Management (IntentRoutingState):

- query: Current query (may be rewritten)
- original_query: Original user query
- intent: FACT/CONCEPT/COMPARISON
- retrieved_docs: Retrieved documents
- retrieval_grade: YES/NO validation
- rewritten_query: Enhanced query if needed
- retry_count: Number of retry attempts (max 1)

## 6. Evaluation Framework (evaluation/judge.py)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          LLM-as-Judge Evaluation                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   Question â”€â”€â”
              â”‚
   Context â”€â”€â”€â”¼â”€â”€â–¶ Judge Prompt â”€â”€â–¶ LLM â”€â”€â–¶ Scores
              â”‚                              (JSON)
   Answer  -â”€â”€â”˜

   Metrics:
   - Correctness (1-5): Answer accuracy
   - Relevance (1-5): Query alignment
   - Faithfulness (1-5): Context grounding
```

## ğŸ”„ Complete Workflow

### Workflow 1: Document Ingestion (ragchain ingest)
```
1. Fetch Data Sources
   â”œâ”€ TIOBE Index â†’ Top 50 languages
   â”œâ”€ Wikipedia API â†’ Language articles
   â””â”€ Conceptual Pages â†’ Bridge topics

2. Process Documents
   â”œâ”€ Parse HTML/Text
   â”œâ”€ Chunk (2500 chars, 500 overlap)
   â””â”€ Add metadata (title, source, etc.)

3. Generate Embeddings
   â”œâ”€ Use qwen3-embedding:4b
   â””â”€ 1024-dimensional vectors

4. Store in Chroma
   â”œâ”€ Upsert to vector store
   â””â”€ Index for semantic search
```
### Workflow 2: Direct Search (ragchain search)
```
User Query
    â”‚
    â–¼
Ensemble Retriever
    â”œâ”€ BM25 Retrieval
    â”œâ”€ Chroma Retrieval
    â””â”€ RRF Fusion
    â”‚
    â–¼
Return Top-K Results
```
### Workflow 3: RAG Answer Generation (ragchain ask)
```
1. User Query
   â”‚
   â–¼
2. Intent Classification
   â”œâ”€ FACT â†’ Keyword-heavy
   â”œâ”€ CONCEPT â†’ Balanced
   â””â”€ COMPARISON â†’ Semantic-heavy
   â”‚
   â–¼
3. Adaptive Retrieval
   â”œâ”€ Apply intent-specific weights
   â””â”€ Retrieve documents
   â”‚
   â–¼
4. Relevance Grading
   â”œâ”€ LLM validates relevance
   â””â”€ Decision: YES/NO
   â”‚
   â”œâ”€â”€â”€ YES â”€â”€â”€â”€â–¶ 5. Generate Answer
   â”‚                 â”œâ”€ Build context
   â”‚                 â”œâ”€ Apply RAG template
   â”‚                 â””â”€ LLM generates answer
   â”‚
   â””â”€â”€â”€ NO â”€â”€â”€â”€â”€â–¶ 4a. Query Rewriting
                     â”œâ”€ Enhance with keywords
                     â””â”€ Retry retrieval (once)
```
### Workflow 4: Evaluation (ragchain evaluate)

```
1. Load Test Questions (20 diverse queries)
   â”‚
   â–¼
2. For each question:
   â”œâ”€ Run full RAG pipeline
   â”œâ”€ Generate answer
   â””â”€ Collect context
   â”‚
   â–¼
3. LLM-as-Judge Evaluation
   â”œâ”€ Score correctness (1-5)
   â”œâ”€ Score relevance (1-5)
   â””â”€ Score faithfulness (1-5)
   â”‚
   â–¼
4. Aggregate Results
   â””â”€ Display averages
```

